{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fce7707e",
      "metadata": {
        "id": "fce7707e"
      },
      "source": [
        "# Introduction to Bayesian Sampling\n",
        "\n",
        "This notebook is part of a tutorial on \"Practical Bayesian Modeling with PyMC\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48c2f26e",
      "metadata": {
        "id": "48c2f26e"
      },
      "source": [
        "[Click here to run this notebook on Colab](https://colab.research.google.com/github/AllenDowney/SurveyDataPyMC/blob/main/notebooks/00_intro.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fce89fc0",
      "metadata": {
        "id": "fce89fc0"
      },
      "outputs": [],
      "source": [
        "# Get utils.py\n",
        "\n",
        "from os.path import basename, exists\n",
        "\n",
        "\n",
        "def download(url):\n",
        "    filename = basename(url)\n",
        "    if not exists(filename):\n",
        "        from urllib.request import urlretrieve\n",
        "\n",
        "        local, _ = urlretrieve(url, filename)\n",
        "        print(\"Downloaded \" + local)\n",
        "\n",
        "\n",
        "download(\"https://github.com/AllenDowney/SurveyDataPyMC/raw/main/notebooks/utils.py\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f24d9f87",
      "metadata": {
        "id": "f24d9f87"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pymc as pm\n",
        "import arviz as az\n",
        "\n",
        "from utils import value_counts, decorate, plot_prior"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "860f08d5",
      "metadata": {
        "id": "860f08d5"
      },
      "outputs": [],
      "source": [
        "# Make the figures smaller to save some screen real estate\n",
        "plt.rcParams[\"figure.dpi\"] = 75\n",
        "plt.rcParams[\"figure.figsize\"] = [6, 3.5]\n",
        "plt.rcParams[\"axes.titlelocation\"] = \"left\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6a9405e",
      "metadata": {
        "id": "a6a9405e"
      },
      "source": [
        "## PyMC is a RNG\n",
        "\n",
        "Suppose we ask 1000 people to flip a coin and report the result.\n",
        "In this case, we know the probability is 0.5, and we can generate a synthetic sample like this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43eb6e01",
      "metadata": {
        "id": "43eb6e01"
      },
      "outputs": [],
      "source": [
        "# Fill this in\n",
        "\n",
        "with pm.Model() as model:\n",
        "    p = 0.5\n",
        "    y = pm.Bernoulli(\"y\", p=p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3550be83",
      "metadata": {
        "id": "3550be83"
      },
      "outputs": [],
      "source": [
        "with model:\n",
        "    idata = pm.sample_prior_predictive(draws=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29062a7f",
      "metadata": {
        "id": "29062a7f"
      },
      "outputs": [],
      "source": [
        "idata.prior['y'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c02d4571",
      "metadata": {
        "id": "c02d4571"
      },
      "outputs": [],
      "source": [
        "y_data = idata.prior['y'].to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12ccf7a5",
      "metadata": {
        "id": "12ccf7a5"
      },
      "source": [
        "## Uncertain p\n",
        "\n",
        "Now suppose we ask 1000 people to answer a factual question.\n",
        "We imagine that some people are more likely than others to get it right, so we can let the probability of success vary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48f019a5",
      "metadata": {
        "id": "48f019a5"
      },
      "outputs": [],
      "source": [
        "# Modify this\n",
        "\n",
        "with pm.Model() as model:\n",
        "    p = 0.5\n",
        "    y = pm.Bernoulli(\"y\", p=p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dd1f023",
      "metadata": {
        "id": "6dd1f023"
      },
      "outputs": [],
      "source": [
        "with model:\n",
        "    idata = pm.sample_prior_predictive(draws=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97083281",
      "metadata": {
        "id": "97083281"
      },
      "outputs": [],
      "source": [
        "plot_prior(idata)\n",
        "decorate()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f8c2626",
      "metadata": {
        "id": "5f8c2626"
      },
      "source": [
        "## Latent propensity\n",
        "\n",
        "Now suppose we ask 1000 people if they are happy.\n",
        "We can imagine that each person has a latent happiness factor, which influences their tendency to say they are happy.\n",
        "\n",
        "Specifically, we'll assume the distribution of the factor is Normal, and use the sigmoid function (aka expit, aka inverse logit) to map from log odds to probability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cb381c1",
      "metadata": {
        "id": "5cb381c1"
      },
      "outputs": [],
      "source": [
        "# Modify this\n",
        "\n",
        "with pm.Model() as model:\n",
        "    z = pm.Normal(\"z\", mu=0, sigma=1)\n",
        "    p = pm.math.sigmoid(z)\n",
        "    y = pm.Bernoulli(\"y\", p=p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "598046c1",
      "metadata": {
        "id": "598046c1"
      },
      "outputs": [],
      "source": [
        "with model:\n",
        "    idata = pm.sample_prior_predictive(draws=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "531de0f0",
      "metadata": {
        "id": "531de0f0"
      },
      "outputs": [],
      "source": [
        "plot_prior(idata)\n",
        "decorate()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3eaaa492",
      "metadata": {
        "id": "3eaaa492"
      },
      "source": [
        "Let's save the result from this model and suppose it's actual data we collected in a survey."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db4f1825",
      "metadata": {
        "id": "db4f1825"
      },
      "outputs": [],
      "source": [
        "y_data = idata.prior['y'].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73ba4244",
      "metadata": {
        "id": "73ba4244"
      },
      "outputs": [],
      "source": [
        "from scipy.special import logit\n",
        "\n",
        "ref_val = logit(y_data.mean())\n",
        "ref_val"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0067218c",
      "metadata": {
        "id": "0067218c"
      },
      "source": [
        "## Observed data\n",
        "\n",
        "Now we'll use the same model, but now instead of generating `y`, we treat `y` as an observed variable.\n",
        "\n",
        "Instead of `sample_prior_predictive`, which uses known parameters of the model to generate data, we'll use `sample`, which uses the data to infer the parameters of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbd6fb2e",
      "metadata": {
        "id": "fbd6fb2e"
      },
      "outputs": [],
      "source": [
        "# Modify this\n",
        "\n",
        "with pm.Model() as model:\n",
        "    z = pm.Normal(\"z\", mu=0, sigma=1)\n",
        "    p = pm.math.sigmoid(z)\n",
        "    y = pm.Bernoulli(\"y\", p=p, observed=y_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a1ad76f",
      "metadata": {
        "id": "5a1ad76f"
      },
      "outputs": [],
      "source": [
        "with model:\n",
        "    idata = pm.sample(draws=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d3c045b",
      "metadata": {
        "id": "4d3c045b"
      },
      "source": [
        "Now the posterior distribution represents what we believe about the `z` after seeing the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fb1c6e8",
      "metadata": {
        "id": "7fb1c6e8"
      },
      "outputs": [],
      "source": [
        "az.plot_posterior(idata, ref_val=ref_val)\n",
        "decorate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jQoMcf2HL7z4"
      },
      "id": "jQoMcf2HL7z4",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}